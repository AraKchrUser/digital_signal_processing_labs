{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203f798c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:56:43.460602Z",
     "start_time": "2023-05-29T08:56:40.914705Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch.utils.data as data_utils\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pymorphy2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ce75bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:56:43.507102Z",
     "start_time": "2023-05-29T08:56:43.463589Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev)\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3e272b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:56:43.522783Z",
     "start_time": "2023-05-29T08:56:43.509103Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_file(path, arr):\n",
    "    with open(path, 'wb') as f:\n",
    "        np.save(f, arr)\n",
    "    return\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        arr = np.load(f)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f270a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:56:43.538440Z",
     "start_time": "2023-05-29T08:56:43.525790Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    from string import punctuation\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    return [w.lower() for w in tokens if w not in punctuation]\n",
    "\n",
    "def morph_analyze(w, morph):\n",
    "    return morph.parse(w)[0].normal_form\n",
    "\n",
    "def build_vocab(data):\n",
    "    vocab = dict()\n",
    "    freqdist = nltk.FreqDist()\n",
    "    for s in data:\n",
    "        for w in s:\n",
    "            freqdist[w] += 1\n",
    "    cwords = freqdist.most_common(10_000)\n",
    "    for i, w in enumerate(cwords):\n",
    "        vocab[w[0]] = i + 1\n",
    "    return vocab\n",
    "\n",
    "def w2i(data, vocab):\n",
    "    token_is = []\n",
    "    for s in data:\n",
    "        temp = []\n",
    "        for w in s:\n",
    "            if w in vocab.keys():\n",
    "                temp.append(vocab[w])\n",
    "        token_is.append(temp)\n",
    "    return token_is\n",
    "\n",
    "def pad(tokens, max_len):\n",
    "    pad_i = 0\n",
    "    x_pad = []\n",
    "    for s in tokens:\n",
    "        if len(s) < max_len:\n",
    "            while len(s) < max_len:\n",
    "                s.insert(len(s), pad_i)\n",
    "            x_pad.append(s)\n",
    "        else:\n",
    "            x_pad.append(s[:max_len])\n",
    "    return x_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44fa14d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:56:48.999615Z",
     "start_time": "2023-05-29T08:56:43.540440Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel('../2/X_y_train.xlsx')\n",
    "test = pd.read_excel('../2/X_y_test.xlsx')\n",
    "X_train, y_train, X_test, y_test = (train.drop(['Class'], axis=1).Text, train.Class, \n",
    "                                    test.drop(['Class'], axis=1).Text, test.Class)\n",
    "y_train = y_train.apply(lambda x: x if x == 1 else 0).values\n",
    "y_test = y_test.apply(lambda x: x if x == 1 else 0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7310c011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:57:33.656429Z",
     "start_time": "2023-05-29T08:56:49.001928Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tokens = [tokenize(s) for s in X_train.values]\n",
    "X_test_tokens = [tokenize(s) for s in X_test.values]\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "X_train_tokens = [[morph_analyze(w, morph) for w in s] for s in X_train_tokens]\n",
    "X_test_tokens = [[morph_analyze(w, morph) for w in s] for s in X_test_tokens]\n",
    "vocab_ = build_vocab(X_train_tokens + X_test_tokens)\n",
    "X_train_wi = w2i(X_train_tokens, vocab_)\n",
    "X_test_wi = w2i(X_test_tokens, vocab_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6e32f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:57:33.688417Z",
     "start_time": "2023-05-29T08:57:33.658410Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "X_train_wi = pad(X_train_wi, max_len=max_len)\n",
    "X_test_wi = pad(X_test_wi, max_len=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bfb2a",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38837bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:57:33.704420Z",
     "start_time": "2023-05-29T08:57:33.690417Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size=len(vocab_), \n",
    "                 embed_dim=100,\n",
    "                 seq_len=max_len, \n",
    "                 type_rnn=None,\n",
    "                 hidden_size=None, \n",
    "                 bidirectional=None,\n",
    "                 n_layer=None):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1,\n",
    "                                      embedding_dim=embed_dim,\n",
    "                                      padding_idx=0)\n",
    "        \n",
    "        self.rnn = type_rnn(\n",
    "            input_size=self.embed_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layer,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * self.seq_len * (1 + bidirectional), 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape(len(x), self.seq_len, self.embed_dim)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        logits = self.fc(x)\n",
    "        return F.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8f172b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:57:33.736427Z",
     "start_time": "2023-05-29T08:57:33.706421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8628, -0.5481],\n",
       "        [-0.7010, -0.6854],\n",
       "        [-0.7844, -0.6096],\n",
       "        [-0.8548, -0.5540],\n",
       "        [-0.7894, -0.6053]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(type_rnn=torch.nn.RNN,\n",
    "          hidden_size=100, \n",
    "          bidirectional=True,\n",
    "          n_layer=3)\n",
    "net(torch.tensor(X_train_wi[:5], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb836eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:57:33.752430Z",
     "start_time": "2023-05-29T08:57:33.739431Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(net, num_epoch, trainset, optimizer, lr, scheduler, log=False):\n",
    "#     loss_f = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        for data in trainset:\n",
    "            X, y = data\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            loss = F.cross_entropy(output, y.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if scheduler is not None: scheduler.step()\n",
    "        \n",
    "        if log:  print('loss ====> ', loss.item())\n",
    "    return net\n",
    "\n",
    "def predict(net, testset):\n",
    "    ans = []\n",
    "    with torch.no_grad():\n",
    "        for data in testset:\n",
    "            X, y = data\n",
    "            output = net(X)\n",
    "            for idx, i in enumerate(output):\n",
    "                ans.append(i.cpu().data.numpy().argmax().item())\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95dcf17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T08:57:33.768433Z",
     "start_time": "2023-05-29T08:57:33.754432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"lr\": [3e-4],\n",
    "    \"epochs\": [5, 10],\n",
    "    \"optimizer\": [optim.AdamW],\n",
    "    \"batch_size\": [512],\n",
    "    \"type_rnn\": [torch.nn.RNN, torch.nn.LSTM, torch.nn.GRU],\n",
    "    \"layers_count\": [3, 5],\n",
    "    \"bidirectional\": [False, True],\n",
    "    \"hidden_size\": [100, 300]\n",
    "}\n",
    "params_list = ParameterGrid(param_grid)\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d456cd93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T09:27:29.571337Z",
     "start_time": "2023-05-29T08:57:33.772441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [29:55<00:00, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "configs = []\n",
    "\n",
    "inputs_train = torch.tensor(X_train_wi, dtype=torch.int32).to(device)\n",
    "targets_train = torch.tensor(y_train, dtype=torch.int32).to(device)\n",
    "\n",
    "inputs_test = torch.tensor(X_test_wi, dtype=torch.int32).to(device)\n",
    "targets_test = torch.tensor(y_test, dtype=torch.int32).to(device)\n",
    "\n",
    "train = data_utils.TensorDataset(inputs_train, targets_train)\n",
    "test = data_utils.TensorDataset(inputs_test, targets_test)\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, shuffle=True, batch_size=batch_size)\n",
    "testset = torch.utils.data.DataLoader(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# grid search\n",
    "for params in tqdm(params_list):\n",
    "    \n",
    "    # get param for pass to network\n",
    "    lr = params[\"lr\"]\n",
    "    epochs = params[\"epochs\"]\n",
    "    optimizer = params[\"optimizer\"]\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    type_rnn = params[\"type_rnn\"]\n",
    "    n_layer = params[\"layers_count\"]\n",
    "    bidirectional = params[\"bidirectional\"]\n",
    "    hidden_size = params[\"hidden_size\"]\n",
    "    \n",
    "    # net build\n",
    "    net = Net(vocab_size=len(vocab_), \n",
    "              embed_dim=100,\n",
    "              seq_len=max_len,\n",
    "              type_rnn=type_rnn,\n",
    "              hidden_size=hidden_size, \n",
    "              bidirectional=bidirectional,\n",
    "              n_layer=n_layer)\n",
    "    net.to(device)\n",
    "\n",
    "    # fit\n",
    "    net = fit(net, epochs, trainset, optimizer, lr, None, False)\n",
    "    \n",
    "    # predict\n",
    "    ans = predict(net, testset)\n",
    "    \n",
    "    # add param in config\n",
    "    config = [epochs, optimizer.__name__, batch_size, type_rnn.__name__, hidden_size,\n",
    "              n_layer, bidirectional, f'{f1_score(y_test, ans, average=\"weighted\"):.5f}']\n",
    "    configs.append(config)\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437ff132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T09:27:29.634351Z",
     "start_time": "2023-05-29T09:27:29.577340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>type_rnn</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.82022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.80032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.79903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.79185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.77956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.77956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.77815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.74031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.74031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.73947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.73947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.73777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.73777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.73527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.73158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.73158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.73158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.71865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.71865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.71864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.71300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.69747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.68051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.67844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.67221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.66696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.66041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.65931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.65713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.65709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.63527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>GRU</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.62046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>RNN</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.57640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.56000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs optimizer  batch_size type_rnn  hidden_size  n_layer  \\\n",
       "0        5     AdamW         512     LSTM          100        5   \n",
       "1        5     AdamW         512     LSTM          100        3   \n",
       "2       10     AdamW         512     LSTM          300        3   \n",
       "3        5     AdamW         512      GRU          100        3   \n",
       "4        5     AdamW         512     LSTM          300        3   \n",
       "5        5     AdamW         512     LSTM          100        5   \n",
       "6        5     AdamW         512     LSTM          100        3   \n",
       "7       10     AdamW         512      RNN          100        5   \n",
       "8       10     AdamW         512      RNN          300        3   \n",
       "9       10     AdamW         512      GRU          100        3   \n",
       "10      10     AdamW         512     LSTM          300        5   \n",
       "11      10     AdamW         512     LSTM          300        3   \n",
       "12       5     AdamW         512     LSTM          300        5   \n",
       "13       5     AdamW         512     LSTM          300        5   \n",
       "14      10     AdamW         512      RNN          100        3   \n",
       "15      10     AdamW         512     LSTM          300        5   \n",
       "16       5     AdamW         512      RNN          100        3   \n",
       "17       5     AdamW         512      GRU          300        3   \n",
       "18      10     AdamW         512     LSTM          100        5   \n",
       "19       5     AdamW         512      GRU          100        5   \n",
       "20       5     AdamW         512      GRU          300        5   \n",
       "21      10     AdamW         512      RNN          100        5   \n",
       "22      10     AdamW         512      GRU          100        3   \n",
       "23      10     AdamW         512      GRU          300        5   \n",
       "24      10     AdamW         512      GRU          100        5   \n",
       "25       5     AdamW         512      RNN          300        5   \n",
       "26       5     AdamW         512      GRU          100        5   \n",
       "27      10     AdamW         512      RNN          300        3   \n",
       "28       5     AdamW         512      RNN          300        3   \n",
       "29       5     AdamW         512      RNN          300        5   \n",
       "30       5     AdamW         512      GRU          100        3   \n",
       "31       5     AdamW         512     LSTM          300        3   \n",
       "32      10     AdamW         512     LSTM          100        3   \n",
       "33      10     AdamW         512      GRU          300        5   \n",
       "34      10     AdamW         512     LSTM          100        5   \n",
       "35       5     AdamW         512      RNN          300        3   \n",
       "36       5     AdamW         512      RNN          100        3   \n",
       "37      10     AdamW         512      GRU          300        3   \n",
       "38       5     AdamW         512      RNN          100        5   \n",
       "39      10     AdamW         512      GRU          300        3   \n",
       "40       5     AdamW         512      GRU          300        5   \n",
       "41      10     AdamW         512      RNN          100        3   \n",
       "42      10     AdamW         512      RNN          300        5   \n",
       "43      10     AdamW         512      RNN          300        5   \n",
       "44      10     AdamW         512      GRU          100        5   \n",
       "45       5     AdamW         512      GRU          300        3   \n",
       "46       5     AdamW         512      RNN          100        5   \n",
       "47      10     AdamW         512     LSTM          100        3   \n",
       "\n",
       "    bidirectional f1_score  \n",
       "0            True  0.82022  \n",
       "1           False  0.80032  \n",
       "2           False  0.80000  \n",
       "3           False  0.79903  \n",
       "4           False  0.79185  \n",
       "5           False  0.77956  \n",
       "6            True  0.77956  \n",
       "7            True  0.77815  \n",
       "8            True  0.76000  \n",
       "9            True  0.76000  \n",
       "10           True  0.75883  \n",
       "11           True  0.75883  \n",
       "12          False  0.75883  \n",
       "13           True  0.75691  \n",
       "14           True  0.74031  \n",
       "15          False  0.74031  \n",
       "16          False  0.73947  \n",
       "17          False  0.73947  \n",
       "18           True  0.73777  \n",
       "19           True  0.73777  \n",
       "20          False  0.73527  \n",
       "21          False  0.73158  \n",
       "22          False  0.73158  \n",
       "23          False  0.73158  \n",
       "24           True  0.72000  \n",
       "25          False  0.71865  \n",
       "26          False  0.71865  \n",
       "27          False  0.71864  \n",
       "28           True  0.71300  \n",
       "29           True  0.70036  \n",
       "30           True  0.70036  \n",
       "31           True  0.69747  \n",
       "32          False  0.69029  \n",
       "33           True  0.68051  \n",
       "34          False  0.68000  \n",
       "35          False  0.68000  \n",
       "36           True  0.68000  \n",
       "37           True  0.67844  \n",
       "38           True  0.67221  \n",
       "39          False  0.66696  \n",
       "40           True  0.66041  \n",
       "41          False  0.65931  \n",
       "42          False  0.65713  \n",
       "43           True  0.65709  \n",
       "44          False  0.63527  \n",
       "45           True  0.62046  \n",
       "46          False  0.57640  \n",
       "47           True  0.56000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(configs)\n",
    "df.columns = ['epochs', 'optimizer', 'batch_size', 'type_rnn', \n",
    "              'hidden_size', 'n_layer', 'bidirectional', 'f1_score']\n",
    "df.sort_values(by='f1_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2b911",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e70fd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T22:29:58.004949Z",
     "start_time": "2023-05-28T22:29:52.420347Z"
    }
   },
   "outputs": [],
   "source": [
    "path_ = '../2/'\n",
    "train = pd.read_excel(path_ + 'X_y_train.xlsx')\n",
    "test = pd.read_excel(path_ + 'X_y_test.xlsx')\n",
    "X_train, y_train, X_test, y_test = train.drop(['Class'], axis=1), train.Class, test.drop(['Class'], axis=1), test.Class\n",
    "assert y_train.shape == (X_train.shape[0],) and y_test.shape == (X_test.shape[0], )\n",
    "y_train = y_train.apply(lambda x: x if x == 1 else 0)\n",
    "y_test = y_test.apply(lambda x: x if x == 1 else 0)\n",
    "\n",
    "\n",
    "path_ = '../2/saved/'\n",
    "__train_w2v_pretrain = load_file(path_ + '__train_w2v_pretrain.npy')\n",
    "__test_w2v_pretrain = load_file(path_ + '__test_w2v_pretrain.npy')\n",
    "\n",
    "__train_w2v = load_file(path_ + '__train_w2v.npy')\n",
    "__test_w2v = load_file(path_ + '__test_w2v.npy')\n",
    "\n",
    "__train_fasttext_500 = load_file(path_ + '__train_fasttext_500_10.npy')\n",
    "__test_fasttext_500 = load_file(path_ + '__test_fasttext_500_10.npy')\n",
    "\n",
    "__train_fasttext_pretrain = load_file(path_ + '__train_fasttext_pretrain.npy')\n",
    "__test_fasttext_pretrain = load_file(path_ + '__test_fasttext_pretrain.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d6b5ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T22:29:58.020946Z",
     "start_time": "2023-05-28T22:29:58.006949Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size=len(vocab_), \n",
    "                 embed_dim=300,\n",
    "                 seq_len=max_len,\n",
    "                 conv_layer_count=2, \n",
    "                 stride=1,\n",
    "                 kernel_size=3,\n",
    "                 type_rnn=None,\n",
    "                 hidden_size=None, \n",
    "                 bidirectional=None,\n",
    "                 n_layer=None):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.conv1d_layers = nn.ModuleList([])\n",
    "        out_shape = 1\n",
    "        padding = kernel_size // 2\n",
    "        for i in range(conv_layer_count):\n",
    "            self.conv1d_layers.append(nn.Conv1d(in_channels=embed_dim,\n",
    "                                                out_channels=embed_dim,\n",
    "                                                kernel_size=kernel_size,\n",
    "                                                stride=stride, \n",
    "                                                padding=padding))\n",
    "            out_shape = 1 + (out_shape + 2 * padding - kernel_size) // stride\n",
    "        \n",
    "        self.rnn = type_rnn(\n",
    "            input_size=self.embed_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layer,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * out_shape * (1 + bidirectional), 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, None]\n",
    "        for conv_layer in self.conv1d_layers:\n",
    "            x = F.relu(conv_layer(x))\n",
    "        x = x.reshape(len(x), -1, self.embed_dim)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        logits = self.fc(x)\n",
    "        return F.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d60912f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T22:29:58.084913Z",
     "start_time": "2023-05-28T22:29:58.022947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7234, -0.6638],\n",
       "        [-0.7231, -0.6641],\n",
       "        [-0.7237, -0.6635],\n",
       "        [-0.7239, -0.6633],\n",
       "        [-0.7234, -0.6638]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(type_rnn=torch.nn.RNN,\n",
    "          hidden_size=100, \n",
    "          bidirectional=True,\n",
    "          n_layer=3)\n",
    "net(torch.tensor(__train_w2v_pretrain[:5], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab7ec853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T22:29:58.100915Z",
     "start_time": "2023-05-28T22:29:58.086912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"embeddings\": [(__train_w2v, __test_w2v), \n",
    "                   (__train_fasttext_500, __test_fasttext_500)],\n",
    "    \"lr\": [3e-4],\n",
    "    \"epochs\": [5, 10],\n",
    "    \"optimizer\": [optim.AdamW],\n",
    "    \"batch_size\": [batch_size],\n",
    "    \"layers_count\": [3, 5],\n",
    "    \"kernel_size\": [3],\n",
    "    \"stride\": [1, 3],\n",
    "    \"type_rnn\": [torch.nn.LSTM, torch.nn.GRU],\n",
    "    \"layers_count\": [3, 5],\n",
    "    \"bidirectional\": [True],\n",
    "    \"hidden_size\": [100, 300]\n",
    "}\n",
    "params_list = ParameterGrid(param_grid)\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d05b834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T22:36:41.366582Z",
     "start_time": "2023-05-28T22:29:58.102916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [06:43<00:00,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "configs = []\n",
    "\n",
    "# grid search\n",
    "for params in tqdm(params_list):\n",
    "    \n",
    "    # get param for pass to network\n",
    "    X_train, X_test = params[\"embeddings\"]\n",
    "    lr = params['lr']\n",
    "    epochs = params['epochs']\n",
    "    optimizer = params['optimizer']\n",
    "    batch_size = params['batch_size']\n",
    "    layers_count = params['layers_count']\n",
    "    kernel_size = params['kernel_size']\n",
    "    stride = params['stride']\n",
    "    type_rnn = params[\"type_rnn\"]\n",
    "    n_layer = params[\"layers_count\"]\n",
    "    bidirectional = params[\"bidirectional\"]\n",
    "    hidden_size = params[\"hidden_size\"]\n",
    "    \n",
    "    inputs_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    targets_train = torch.tensor(y_train, dtype=torch.int32).to(device)\n",
    "\n",
    "    inputs_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    targets_test = torch.tensor(y_test, dtype=torch.int32).to(device)\n",
    "\n",
    "    train = data_utils.TensorDataset(inputs_train, targets_train)\n",
    "    test = data_utils.TensorDataset(inputs_test, targets_test)\n",
    "\n",
    "    trainset = torch.utils.data.DataLoader(train, shuffle=True, batch_size=batch_size)\n",
    "    testset = torch.utils.data.DataLoader(test, shuffle=False, batch_size=batch_size)\n",
    "    \n",
    "    # net build\n",
    "    net = Net(vocab_size=len(vocab_), \n",
    "              embed_dim=300, \n",
    "              conv_layer_count=layers_count, \n",
    "              stride=stride, \n",
    "              kernel_size=kernel_size, \n",
    "              seq_len=max_len, \n",
    "              type_rnn=type_rnn,\n",
    "              hidden_size=hidden_size, \n",
    "              bidirectional=bidirectional,\n",
    "              n_layer=n_layer)\n",
    "    net.to(device)\n",
    "\n",
    "    # fit\n",
    "    net = fit(net, epochs, trainset, optimizer, lr, None, False)\n",
    "    \n",
    "    # predict\n",
    "    ans = predict(net, testset)\n",
    "    \n",
    "    # add param in config\n",
    "    config = [epochs, optimizer.__name__, batch_size, layers_count, kernel_size, stride, \n",
    "              type_rnn.__name__, n_layer, bidirectional, hidden_size, f'{f1_score(y_test, ans):.5f}']\n",
    "    configs.append(config)\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d468236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T22:36:41.398584Z",
     "start_time": "2023-05-28T22:36:41.369577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>cnn_layer</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>stride</th>\n",
       "      <th>type_rnn</th>\n",
       "      <th>rnn_layer</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GRU</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>0.89286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.89286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.87719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GRU</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.85185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.84211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>0.70130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>0.70130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>0.70130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>0.68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.65455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs optimizer  batch_size  cnn_layer  kernel_size  stride type_rnn  \\\n",
       "0       10     AdamW         512          5            3       3      GRU   \n",
       "1        5     AdamW         512          5            3       1     LSTM   \n",
       "2       10     AdamW         512          3            3       3      GRU   \n",
       "3       10     AdamW         512          5            3       1      GRU   \n",
       "4       10     AdamW         512          5            3       1     LSTM   \n",
       "..     ...       ...         ...        ...          ...     ...      ...   \n",
       "59      10     AdamW         512          5            3       3     LSTM   \n",
       "60       5     AdamW         512          5            3       1     LSTM   \n",
       "61       5     AdamW         512          5            3       1     LSTM   \n",
       "62      10     AdamW         512          3            3       1      GRU   \n",
       "63      10     AdamW         512          3            3       3      GRU   \n",
       "\n",
       "    rnn_layer  bidirectional  hidden_size f1_score  \n",
       "0           5           True          300  0.89286  \n",
       "1           5           True          100  0.89286  \n",
       "2           3           True          100  0.87719  \n",
       "3           5           True          100  0.85185  \n",
       "4           5           True          100  0.84211  \n",
       "..        ...            ...          ...      ...  \n",
       "59          5           True          300  0.70130  \n",
       "60          5           True          300  0.70130  \n",
       "61          5           True          300  0.70130  \n",
       "62          3           True          300  0.68000  \n",
       "63          3           True          100  0.65455  \n",
       "\n",
       "[64 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(configs)\n",
    "df.columns = ['epochs', 'optimizer', 'batch_size', 'cnn_layer', 'kernel_size', 'stride', \n",
    "              'type_rnn', 'rnn_layer', 'bidirectional', 'hidden_size', 'f1_score']\n",
    "df.sort_values(by='f1_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f53cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
